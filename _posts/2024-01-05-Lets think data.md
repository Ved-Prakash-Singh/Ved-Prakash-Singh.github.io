---
layout: post
title: Lets think data
---
Have you ever wondered, how much data is there in the world? At what accelated velocity, these data are being created? How much of these data are original and how much are duplicate?

Yes, you are right, it is very difficult or near impossible to get these numbers. In this post, I will talk about some of the lower bond approximated numbers based upon certain research organizations. 

Data are in various forms, they are online data, they are in term of physical data like book, paper documents, they are also in stand alone disk storages etc. In this post, I will be focussed around online data, which can be considered as lower bound number.

<ul>
  <li>As per an estimate from International Data Corporation (IDC), the overall online datasize was around <b>64 zettabytes</b> in 2020. </li>
  <li>IDC predicts that the Global Datasphere will grow from 33 Zettabytes in 2018 to <b>175 Zettabytes</b> by 2025. </li>
  <li>One zettabyte is approximately equal to 1 billion terabytes. </li>
  <li>If you were able to store the entire Global Datasphere on DVDs, then you would have a stack of DVDs that could <b> get you to the moon 23 times or circle Earth 222 times</b>.</li>
  <li>If you could download the entire 2025 Global Datasphere at an average of 25 Mb/s, today's average connection speed across the United States, then it would take one person <b>1.8 billion years</b> to do it</li>
  <li>If <b>every person</b> in the world could help and never rest, then you could get it done in <b>81 days</b></li>
  <li>There is 90% replicated data in the global datasphere, with only 10% being unique data.</li>
  <li>A Day in data</li>
  <ul>
    <li> 294 billion emails are sent everyday </li>
    <li> 65 billion messages sent over WhatsApp everyday</li>
    <li> 2 billion minutes of voice and videocall made on WhatsApp everyday </li>
    <li> 3.5 billion seaches made from gogle everyday</li>
    <li> 500 millions tweets are sent everyday </li>
    <li> 4 petabyte of data created by facebook everyday</li>
  </ul>
</ul>

Teaser for subsequent posts: <br>
What fraction of these data are labelled data? How labelling is constraint to use these data for AI algorithms?  What is the data collection and labelling market size? What are the techniques which researchers have came up with to utilize unlabelled data? How large language model grown by structuring problem in such a way that unlabelled data has been used as labelled data.

Reference: <br>
https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf
https://www.visualcapitalist.com/wp-content/uploads/2019/04/data-generated-each-day-wide.html
https://www.statista.com/statistics/1185888/worldwide-global-datasphere-unique-replicated-data/

